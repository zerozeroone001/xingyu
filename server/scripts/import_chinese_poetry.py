#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä» chinese-poetry é¡¹ç›®å¯¼å…¥å”è¯—æ•°æ®

æ•°æ®æº: https://github.com/chinese-poetry/chinese-poetry
"""

import asyncio
import json
import sys
import hashlib
import io
from pathlib import Path
from typing import List, Dict, Any

# è®¾ç½®æ ‡å‡†è¾“å‡ºä¸ºUTF-8ç¼–ç ï¼ˆWindowså…¼å®¹ï¼‰
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from opencc import OpenCC

from app.core.config import settings
from app.models.author import Author
from app.models.poetry import Poetry


# æ•°æ®æºè·¯å¾„
POETRY_DATA_DIR = Path("F:/code/python/chinese-poetry/å…¨å”è¯—")

# åˆ›å»ºç¹ä½“è½¬ç®€ä½“è½¬æ¢å™¨
cc = OpenCC('t2s')  # Traditional to Simplified


def generate_id(text: str) -> int:
    """æ ¹æ®æ–‡æœ¬ç”Ÿæˆå”¯ä¸€çš„æ•´æ•°ID"""
    # ä½¿ç”¨MD5å“ˆå¸Œç”Ÿæˆï¼Œå–å‰16ä½è½¬ä¸ºæ•´æ•°
    hash_obj = hashlib.md5(text.encode('utf-8'))
    hash_hex = hash_obj.hexdigest()[:16]
    return int(hash_hex, 16) % (10**18)  # é™åˆ¶åœ¨18ä½æ•°å­—å†…


def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤å¤šä½™ç©ºæ ¼"""
    return ' '.join(text.split()).strip()


def convert_to_simplified(text: str | None) -> str | None:
    """
    å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡

    Args:
        text: éœ€è¦è½¬æ¢çš„æ–‡æœ¬ï¼Œå¯ä»¥ä¸ºNone

    Returns:
        è½¬æ¢åçš„ç®€ä½“æ–‡æœ¬ï¼Œå¦‚æœè¾“å…¥ä¸ºNoneåˆ™è¿”å›None
    """
    if text is None:
        return None
    return cc.convert(text)


def parse_authors(file_path: Path) -> List[Dict[str, Any]]:
    """è§£æä½œè€…æ•°æ®"""
    print(f"ğŸ“– è¯»å–ä½œè€…æ•°æ®: {file_path}")

    with open(file_path, 'r', encoding='utf-8') as f:
        authors_raw = json.load(f)

    authors = []
    for author_raw in authors_raw:
        # è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
        name = convert_to_simplified(clean_text(author_raw['name']))
        intro = clean_text(author_raw.get('desc', '')) if author_raw.get('desc') else None
        intro = convert_to_simplified(intro)

        author = {
            'id': generate_id(f"author_{author_raw['name']}"),
            'name': name,
            'dynasty': 'å”',
            'intro': intro,
        }
        authors.append(author)

    print(f"âœ… è§£æä½œè€…æ•°æ®å®Œæˆ: {len(authors)} ä½")
    return authors


def parse_poetries(file_path: Path, author_map: Dict[str, int], limit: int = None) -> List[Dict[str, Any]]:
    """è§£æè¯—è¯æ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        poetries_raw = json.load(f)

    poetries = []
    count = 0

    for poetry_raw in poetries_raw:
        if limit and count >= limit:
            break

        # ç»„åˆè¯—å¥
        paragraphs = poetry_raw.get('paragraphs', [])
        content = '\n'.join(paragraphs)

        if not content.strip():
            continue

        author_name = clean_text(poetry_raw.get('author', ''))
        author_id = author_map.get(author_name)

        # æ ¹æ®å†…å®¹åˆ¤æ–­è¯—è¯ç±»å‹
        poem_type = None
        lines = len(paragraphs)
        if lines == 4:
            poem_type = 'ç»å¥'
        elif lines == 8:
            poem_type = 'å¾‹è¯—'
        elif lines > 8:
            poem_type = 'å¤è¯—'

        # å¤„ç†æ ‡é¢˜ï¼ˆæœ€å¤§100å­—ç¬¦ï¼‰å¹¶è½¬æ¢ä¸ºç®€ä½“
        title = clean_text(poetry_raw.get('title', 'æ— é¢˜'))
        title = convert_to_simplified(title)
        if len(title) > 100:
            title = title[:97] + '...'

        # è½¬æ¢å†…å®¹ä¸ºç®€ä½“
        content = convert_to_simplified(content)
        author_name = convert_to_simplified(author_name)

        poetry = {
            'id': generate_id(f"poetry_{poetry_raw.get('title', '')}_{author_name}_{content[:20]}"),
            'title': title,
            'content': content,
            'author_id': author_id,
            'dynasty': 'å”',
            'type': poem_type,
            'tags': None,
            'translation': None,
            'annotation': None,
            'appreciation': None,
            'background': None,
            'read_count': 0,
            'like_count': 0,
            'comment_count': 0,
            'collect_count': 0,
            'status': 1,  # å·²å‘å¸ƒ
        }

        poetries.append(poetry)
        count += 1

    return poetries


async def import_data(limit_per_file: int = None, max_files: int = None):
    """å¯¼å…¥æ•°æ®"""

    # åˆ›å»ºæ•°æ®åº“å¼•æ“
    engine = create_async_engine(
        settings.DATABASE_URL,
        echo=False,  # å…³é—­SQLæ—¥å¿—ï¼Œæé«˜å¯¼å…¥é€Ÿåº¦
        pool_pre_ping=True,
    )

    # åˆ›å»ºä¼šè¯å·¥å‚
    async_session = async_sessionmaker(
        engine,
        class_=AsyncSession,
        expire_on_commit=False,
    )

    try:
        # 1. å¯¼å…¥ä½œè€…æ•°æ®
        print("\n" + "="*60)
        print("ğŸ“š ç¬¬ä¸€æ­¥ï¼šå¯¼å…¥ä½œè€…æ•°æ®")
        print("="*60)

        authors_file = POETRY_DATA_DIR / "authors.tang.json"
        authors_data = parse_authors(authors_file)

        # åˆ›å»ºä½œè€…ååˆ°IDçš„æ˜ å°„
        author_map = {author['name']: author['id'] for author in authors_data}

        async with async_session() as session:
            authors_imported = 0
            authors_skipped = 0

            for author_data in authors_data:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                result = await session.execute(
                    select(Author).where(Author.id == author_data['id'])
                )
                if result.scalar_one_or_none():
                    authors_skipped += 1
                    continue

                author = Author(**author_data)
                session.add(author)
                authors_imported += 1

                if authors_imported % 100 == 0:
                    print(f"   å·²å¯¼å…¥ {authors_imported} ä½ä½œè€…...")

            await session.commit()
            print(f"âœ… ä½œè€…å¯¼å…¥å®Œæˆ: æ–°å¢ {authors_imported} ä½, è·³è¿‡ {authors_skipped} ä½")

        # 2. å¯¼å…¥è¯—è¯æ•°æ®
        print("\n" + "="*60)
        print("ğŸ“š ç¬¬äºŒæ­¥ï¼šå¯¼å…¥è¯—è¯æ•°æ®")
        print("="*60)

        # è·å–æ‰€æœ‰è¯—è¯æ–‡ä»¶
        poetry_files = sorted(POETRY_DATA_DIR.glob("poet.tang.*.json"))

        if max_files:
            poetry_files = poetry_files[:max_files]

        print(f"ğŸ“‚ æ‰¾åˆ° {len(poetry_files)} ä¸ªè¯—è¯æ–‡ä»¶")

        total_poetries_imported = 0
        total_poetries_skipped = 0

        for idx, poetry_file in enumerate(poetry_files, 1):
            print(f"\n[{idx}/{len(poetry_files)}] å¤„ç†æ–‡ä»¶: {poetry_file.name}")

            poetries_data = parse_poetries(poetry_file, author_map, limit_per_file)
            print(f"   è§£æåˆ° {len(poetries_data)} é¦–è¯—")

            async with async_session() as session:
                batch_imported = 0
                batch_skipped = 0

                for poetry_data in poetries_data:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    result = await session.execute(
                        select(Poetry).where(Poetry.id == poetry_data['id'])
                    )
                    if result.scalar_one_or_none():
                        batch_skipped += 1
                        continue

                    poetry = Poetry(**poetry_data)
                    session.add(poetry)
                    batch_imported += 1

                    if batch_imported % 100 == 0:
                        await session.commit()
                        print(f"   å·²å¯¼å…¥ {batch_imported} é¦–...")

                await session.commit()
                total_poetries_imported += batch_imported
                total_poetries_skipped += batch_skipped

                print(f"   âœ… æœ¬æ–‡ä»¶: æ–°å¢ {batch_imported} é¦–, è·³è¿‡ {batch_skipped} é¦–")

        print(f"\nâœ… è¯—è¯å¯¼å…¥å®Œæˆ: æ€»æ–°å¢ {total_poetries_imported} é¦–, è·³è¿‡ {total_poetries_skipped} é¦–")

        # 3. ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡")
        print("="*60)

        async with async_session() as session:
            # ç»Ÿè®¡ä½œè€…
            result = await session.execute(select(Author))
            total_authors = len(result.scalars().all())
            print(f"   ä½œè€…æ€»æ•°: {total_authors}")

            # ç»Ÿè®¡è¯—è¯
            result = await session.execute(select(Poetry))
            total_poetries = len(result.scalars().all())
            print(f"   è¯—è¯æ€»æ•°: {total_poetries}")

            # æŒ‰ç±»å‹ç»Ÿè®¡
            for poem_type in ['ç»å¥', 'å¾‹è¯—', 'å¤è¯—']:
                result = await session.execute(
                    select(Poetry).where(Poetry.type == poem_type)
                )
                count = len(result.scalars().all())
                print(f"   {poem_type}: {count} é¦–")

        print("\nâœ… å¯¼å…¥å®Œæˆï¼")

    except Exception as e:
        print(f"\nâŒ å¯¼å…¥å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        await engine.dispose()


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸš€ æ˜Ÿè¯­è¯—è¯å¹³å° - å”è¯—æ•°æ®å¯¼å…¥å·¥å…·")
    print("="*60)
    print(f"ğŸ“‚ æ•°æ®æº: {POETRY_DATA_DIR}")
    print()

    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not POETRY_DATA_DIR.exists():
        print(f"âŒ é”™è¯¯: æ•°æ®ç›®å½•ä¸å­˜åœ¨: {POETRY_DATA_DIR}")
        print("\nè¯·å…ˆå…‹éš† chinese-poetry é¡¹ç›®:")
        print("   cd F:/code/python")
        print("   git clone https://github.com/chinese-poetry/chinese-poetry.git")
        sys.exit(1)

    # é…ç½®å¯¼å…¥å‚æ•°
    import argparse
    parser = argparse.ArgumentParser(description='å¯¼å…¥å”è¯—æ•°æ®')
    parser.add_argument('--limit', type=int, help='æ¯ä¸ªæ–‡ä»¶æœ€å¤šå¯¼å…¥çš„è¯—è¯æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    parser.add_argument('--max-files', type=int, help='æœ€å¤šå¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    args = parser.parse_args()

    if args.limit:
        print(f"âš ï¸  æµ‹è¯•æ¨¡å¼: æ¯ä¸ªæ–‡ä»¶æœ€å¤šå¯¼å…¥ {args.limit} é¦–è¯—")
    if args.max_files:
        print(f"âš ï¸  æµ‹è¯•æ¨¡å¼: æœ€å¤šå¤„ç† {args.max_files} ä¸ªæ–‡ä»¶")

    print()

    try:
        asyncio.run(import_data(
            limit_per_file=args.limit,
            max_files=args.max_files
        ))
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­å¯¼å…¥")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
