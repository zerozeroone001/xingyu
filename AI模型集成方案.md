# è¯—è¯ç¨‹åº - AIæ¨¡å‹é›†æˆæ–¹æ¡ˆ

## ä¸€ã€AIåŠŸèƒ½æ€»è§ˆ

### 1.1 æ ¸å¿ƒAIèƒ½åŠ›

| åŠŸèƒ½ | æŠ€æœ¯æ–¹æ¡ˆ | ä¼˜å…ˆçº§ | å¼€å‘å‘¨æœŸ | GPUéœ€æ±‚ |
|------|---------|--------|---------|---------|
| **æ™ºèƒ½æ¨è** | ååŒè¿‡æ»¤ + å†…å®¹æ¨è + æ·±åº¦å­¦ä¹  | â­â­â­â­â­ | 2-3å‘¨ | å¯é€‰ |
| **AIè¯—è¯ç”Ÿæˆ** | GPT-2ä¸­æ–‡ / ChatGLM | â­â­â­â­ | 2-3å‘¨ | æ¨è |
| **æƒ…æ„Ÿåˆ†æ** | RoBERTaæƒ…æ„Ÿæ¨¡å‹ | â­â­â­â­ | 1å‘¨ | å¯é€‰ |
| **æœä»£/ä½œè€…è¯†åˆ«** | BERTæ–‡æœ¬åˆ†ç±» | â­â­â­ | 1-2å‘¨ | å¯é€‰ |
| **è¯­ä¹‰æœç´¢** | Sentence-BERT + Faiss | â­â­â­â­â­ | 1-2å‘¨ | å¯é€‰ |
| **OCRè¯†åˆ«** | PaddleOCR | â­â­â­ | 1å‘¨ | å¯é€‰ |
| **æ™ºèƒ½é—®ç­”** | RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) | â­â­â­ | 2-3å‘¨ | æ¨è |
| **è¯—è¯çº é”™** | BERT + è§„åˆ™å¼•æ“ | â­â­ | 1-2å‘¨ | å¯é€‰ |

---

## äºŒã€è¯¦ç»†åŠŸèƒ½è®¾è®¡

### 2.1 æ™ºèƒ½æ¨èç³»ç»Ÿ ğŸ¯

#### åŠŸèƒ½æè¿°
åŸºäºç”¨æˆ·è¡Œä¸ºã€è¯—è¯ç‰¹å¾ã€ç¤¾äº¤å…³ç³»ç­‰å¤šç»´åº¦æ•°æ®ï¼Œä¸ºç”¨æˆ·æ™ºèƒ½æ¨èæ„Ÿå…´è¶£çš„è¯—è¯ã€‚

#### æŠ€æœ¯æ¶æ„

```
ç”¨æˆ·è¡Œä¸ºæ•°æ®
    â†“
ç‰¹å¾å·¥ç¨‹
    â”œâ”€â†’ ç”¨æˆ·ç‰¹å¾ï¼ˆå¹´é¾„ã€åœ°åŸŸã€å…´è¶£ï¼‰
    â”œâ”€â†’ è¯—è¯ç‰¹å¾ï¼ˆæœä»£ã€ç±»å‹ã€ä¸»é¢˜ã€æƒ…æ„Ÿï¼‰
    â”œâ”€â†’ äº¤äº’ç‰¹å¾ï¼ˆç‚¹èµã€æ”¶è—ã€æµè§ˆæ—¶é•¿ï¼‰
    â””â”€â†’ ä¸Šä¸‹æ–‡ç‰¹å¾ï¼ˆæ—¶é—´ã€èŠ‚æ—¥ã€å¤©æ°”ï¼‰
        â†“
æ¨èç®—æ³•
    â”œâ”€â†’ [å¬å›å±‚] ååŒè¿‡æ»¤ (å¿«é€Ÿç­›é€‰å€™é€‰)
    â”œâ”€â†’ [å¬å›å±‚] å†…å®¹æ¨è (åŸºäºç›¸ä¼¼åº¦)
    â”œâ”€â†’ [æ’åºå±‚] æ·±åº¦å­¦ä¹ æ¨¡å‹ (ç²¾å‡†æ’åº)
    â””â”€â†’ [é‡æ’å±‚] è§„åˆ™å¼•æ“ (å¤šæ ·æ€§ã€æ–°é¢–æ€§)
        â†“
æ¨èç»“æœ
```

#### å®ç°æ–¹æ¡ˆ

##### æ–¹æ¡ˆä¸€ï¼šååŒè¿‡æ»¤ï¼ˆåˆæœŸæ¨èï¼Œä¸éœ€è¦GPUï¼‰

```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd

class CollaborativeFiltering:
    """ååŒè¿‡æ»¤æ¨è"""

    def __init__(self, db_session):
        self.db = db_session
        self.user_item_matrix = None  # ç”¨æˆ·-è¯—è¯äº¤äº’çŸ©é˜µ
        self.similarity_matrix = None  # ç›¸ä¼¼åº¦çŸ©é˜µ

    async def build_matrix(self):
        """æ„å»ºç”¨æˆ·-è¯—è¯äº¤äº’çŸ©é˜µ"""
        # è·å–æ‰€æœ‰ç”¨æˆ·äº¤äº’æ•°æ®ï¼ˆç‚¹èµã€æ”¶è—ã€æµè§ˆï¼‰
        interactions = await self.db.execute(
            """
            SELECT user_id, poetry_id,
                   SUM(CASE WHEN action='like' THEN 3
                            WHEN action='collect' THEN 5
                            WHEN action='read' THEN 1
                            ELSE 0 END) as score
            FROM user_interactions
            GROUP BY user_id, poetry_id
            """
        )

        # æ„å»ºçŸ©é˜µ
        df = pd.DataFrame(interactions)
        self.user_item_matrix = df.pivot(
            index='user_id',
            columns='poetry_id',
            values='score'
        ).fillna(0)

        # è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦ï¼ˆåŸºäºç”¨æˆ·ï¼‰
        self.similarity_matrix = cosine_similarity(self.user_item_matrix)

    async def recommend(self, user_id: int, top_k: int = 10):
        """
        ä¸ºç”¨æˆ·æ¨èè¯—è¯

        Args:
            user_id: ç”¨æˆ·ID
            top_k: æ¨èæ•°é‡

        Returns:
            æ¨èçš„è¯—è¯IDåˆ—è¡¨
        """
        if user_id not in self.user_item_matrix.index:
            # æ–°ç”¨æˆ·ï¼šæ¨èçƒ­é—¨è¯—è¯
            return await self.get_popular_poetries(top_k)

        # æ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·
        user_idx = self.user_item_matrix.index.get_loc(user_id)
        similar_users = self.similarity_matrix[user_idx].argsort()[-10:][::-1]

        # èšåˆç›¸ä¼¼ç”¨æˆ·å–œæ¬¢çš„è¯—è¯
        recommendations = []
        user_interacted = set(
            self.user_item_matrix.iloc[user_idx][
                self.user_item_matrix.iloc[user_idx] > 0
            ].index
        )

        for sim_user_idx in similar_users:
            if sim_user_idx == user_idx:
                continue

            sim_user_items = self.user_item_matrix.iloc[sim_user_idx]
            for poetry_id, score in sim_user_items[sim_user_items > 0].items():
                if poetry_id not in user_interacted:
                    recommendations.append({
                        'poetry_id': poetry_id,
                        'score': score * self.similarity_matrix[user_idx][sim_user_idx]
                    })

        # æŒ‰åˆ†æ•°æ’åº
        recommendations = sorted(
            recommendations,
            key=lambda x: x['score'],
            reverse=True
        )[:top_k]

        return [r['poetry_id'] for r in recommendations]

    async def get_popular_poetries(self, top_k: int):
        """è·å–çƒ­é—¨è¯—è¯ï¼ˆå†·å¯åŠ¨ï¼‰"""
        result = await self.db.execute(
            """
            SELECT id FROM poetry
            ORDER BY (like_count * 3 + collect_count * 5 + read_count) DESC
            LIMIT :limit
            """,
            {"limit": top_k}
        )
        return [row[0] for row in result]
```

##### æ–¹æ¡ˆäºŒï¼šæ·±åº¦å­¦ä¹ æ¨èï¼ˆåæœŸä¼˜åŒ–ï¼Œå»ºè®®ä½¿ç”¨GPUï¼‰

```python
import torch
import torch.nn as nn

class DeepRecommender(nn.Module):
    """æ·±åº¦å­¦ä¹ æ¨èæ¨¡å‹ï¼ˆWide & Deepæ¶æ„ï¼‰"""

    def __init__(self, n_users, n_poetries, embedding_dim=64):
        super().__init__()

        # Wideéƒ¨åˆ†ï¼šçº¿æ€§æ¨¡å‹ï¼ˆè®°å¿†èƒ½åŠ›ï¼‰
        self.wide = nn.Linear(n_users + n_poetries, 1)

        # Deepéƒ¨åˆ†ï¼šæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰
        self.user_embedding = nn.Embedding(n_users, embedding_dim)
        self.poetry_embedding = nn.Embedding(n_poetries, embedding_dim)

        self.deep = nn.Sequential(
            nn.Linear(embedding_dim * 2, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 1)
        )

    def forward(self, user_ids, poetry_ids, user_features, poetry_features):
        # Wideéƒ¨åˆ†
        wide_input = torch.cat([user_features, poetry_features], dim=1)
        wide_out = self.wide(wide_input)

        # Deepéƒ¨åˆ†
        user_emb = self.user_embedding(user_ids)
        poetry_emb = self.poetry_embedding(poetry_ids)
        deep_input = torch.cat([user_emb, poetry_emb], dim=1)
        deep_out = self.deep(deep_input)

        # ç»„åˆ
        output = torch.sigmoid(wide_out + deep_out)
        return output


class RecommendationService:
    """æ¨èæœåŠ¡"""

    def __init__(self):
        self.model = DeepRecommender(
            n_users=100000,
            n_poetries=50000,
            embedding_dim=64
        )
        self.model.load_state_dict(torch.load('models/recommender.pth'))
        self.model.eval()

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)

    async def predict(self, user_id: int, poetry_ids: list):
        """
        é¢„æµ‹ç”¨æˆ·å¯¹è¯—è¯çš„å…´è¶£åˆ†æ•°

        Returns:
            {poetry_id: score} å­—å…¸
        """
        # å‡†å¤‡è¾“å…¥æ•°æ®
        user_ids = torch.tensor([user_id] * len(poetry_ids)).to(self.device)
        poetry_ids_tensor = torch.tensor(poetry_ids).to(self.device)

        # è·å–ç‰¹å¾
        user_features = await self.get_user_features(user_id)
        poetry_features = await self.get_poetry_features(poetry_ids)

        # é¢„æµ‹
        with torch.no_grad():
            scores = self.model(
                user_ids,
                poetry_ids_tensor,
                user_features,
                poetry_features
            )

        # è¿”å›ç»“æœ
        results = {
            pid: score.item()
            for pid, score in zip(poetry_ids, scores)
        }
        return results

    async def recommend(self, user_id: int, top_k: int = 10):
        """æ¨èè¯—è¯"""
        # 1. å¬å›å€™é€‰ï¼ˆå¿«é€Ÿç­›é€‰1000ä¸ªå€™é€‰ï¼‰
        candidates = await self.recall_candidates(user_id, n=1000)

        # 2. ç²¾å‡†æ’åºï¼ˆæ·±åº¦æ¨¡å‹ï¼‰
        scores = await self.predict(user_id, candidates)

        # 3. é‡æ’åºï¼ˆå¤šæ ·æ€§ã€æ–°é¢–æ€§ï¼‰
        final_recommendations = await self.rerank(
            user_id,
            scores,
            top_k
        )

        return final_recommendations
```

#### æ•°æ®å­˜å‚¨

```python
# Redisç¼“å­˜æ¨èç»“æœ
class RecommendationCache:
    """æ¨èç»“æœç¼“å­˜"""

    def __init__(self, redis_client):
        self.redis = redis_client

    async def get(self, user_id: int):
        """è·å–ç¼“å­˜çš„æ¨è"""
        key = f"recommend:user:{user_id}"
        result = await self.redis.get(key)
        if result:
            return json.loads(result)
        return None

    async def set(self, user_id: int, recommendations: list, ttl: int = 3600):
        """ç¼“å­˜æ¨èç»“æœï¼ˆ1å°æ—¶ï¼‰"""
        key = f"recommend:user:{user_id}"
        await self.redis.setex(
            key,
            ttl,
            json.dumps(recommendations)
        )
```

---

### 2.2 AIè¯—è¯ç”Ÿæˆ âœï¸

#### åŠŸèƒ½æè¿°
ç”¨æˆ·è¾“å…¥ä¸»é¢˜ã€é£æ ¼ã€æœä»£ç­‰æ¡ä»¶ï¼ŒAIè‡ªåŠ¨ç”Ÿæˆè¯—è¯ã€‚

#### åº”ç”¨åœºæ™¯
1. **åˆ›ä½œè¾…åŠ©**ï¼šç”¨æˆ·è¾“å…¥ä¸»é¢˜ï¼ŒAIç”Ÿæˆè¯—è¯åˆç¨¿
2. **é£èŠ±ä»¤AIå¯¹æ‰‹**ï¼šä¸AIå¯¹æˆ˜é£èŠ±ä»¤
3. **è¯—è¯ç»­å†™**ï¼šç»™å‡ºå‰å‡ å¥ï¼ŒAIç»­å†™
4. **é£æ ¼ä»¿å†™**ï¼šä»¿å†™ç‰¹å®šè¯—äººçš„é£æ ¼

#### æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | æ¨¡å‹ | æ•ˆæœ | é€Ÿåº¦ | GPUéœ€æ±‚ | æ¨è |
|------|------|------|------|---------|------|
| **è½»é‡æ–¹æ¡ˆ** | GPT-2-Small (117M) | â­â­â­ | å¿« | CPUå¯ | åˆæœŸ |
| **å¹³è¡¡æ–¹æ¡ˆ** | GPT-2-Medium (345M) | â­â­â­â­ | ä¸­ç­‰ | æ¨èGPU | â­ |
| **é«˜è´¨é‡æ–¹æ¡ˆ** | ChatGLM-6B | â­â­â­â­â­ | æ…¢ | å¿…é¡»GPU | åæœŸ |

#### å®ç°ä»£ç 

```python
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig
import torch

class PoetryGenerator:
    """è¯—è¯ç”Ÿæˆå™¨"""

    def __init__(self, model_name="uer/gpt2-chinese-poetry"):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            model_name: æ¨¡å‹åç§°ï¼Œå¯é€‰ï¼š
                - "uer/gpt2-chinese-poetry" (è½»é‡ï¼ŒCPUå¯ç”¨)
                - "THUDM/chatglm-6b" (é«˜è´¨é‡ï¼Œéœ€è¦GPU)
        """
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,  # ä½¿ç”¨åŠç²¾åº¦èŠ‚çœæ˜¾å­˜
            device_map="auto"  # è‡ªåŠ¨åˆ†é…åˆ°GPU/CPU
        )
        self.model.eval()

        # ç”Ÿæˆé…ç½®
        self.generation_config = GenerationConfig(
            max_length=100,
            num_return_sequences=1,
            no_repeat_ngram_size=2,  # é¿å…é‡å¤
            top_k=50,
            top_p=0.95,
            temperature=0.8,
            do_sample=True,
            pad_token_id=self.tokenizer.pad_token_id,
            eos_token_id=self.tokenizer.eos_token_id
        )

    async def generate(
        self,
        prompt: str,
        style: str = "äº”è¨€ç»å¥",
        dynasty: str = "å”ä»£",
        num_return: int = 3
    ) -> list[str]:
        """
        ç”Ÿæˆè¯—è¯

        Args:
            prompt: ä¸»é¢˜æˆ–é¦–å¥ï¼Œå¦‚"æ˜æœˆ"ã€"æ˜¥å¤©"
            style: è¯—è¯é£æ ¼ï¼Œå¦‚"äº”è¨€ç»å¥"ã€"ä¸ƒè¨€å¾‹è¯—"ã€"è¯"
            dynasty: æœä»£é£æ ¼ï¼Œå¦‚"å”ä»£"ã€"å®‹ä»£"
            num_return: è¿”å›æ•°é‡

        Returns:
            ç”Ÿæˆçš„è¯—è¯åˆ—è¡¨
        """
        # æ„é€ æç¤ºè¯
        input_text = self._build_prompt(prompt, style, dynasty)

        # Tokenize
        inputs = self.tokenizer(
            input_text,
            return_tensors="pt",
            padding=True
        ).to(self.model.device)

        # ç”Ÿæˆ
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                generation_config=self.generation_config,
                num_return_sequences=num_return
            )

        # è§£ç 
        generated_texts = [
            self.tokenizer.decode(output, skip_special_tokens=True)
            for output in outputs
        ]

        # åå¤„ç†
        poetries = [
            self._post_process(text, style)
            for text in generated_texts
        ]

        return poetries

    def _build_prompt(self, prompt: str, style: str, dynasty: str) -> str:
        """æ„é€ æç¤ºè¯"""
        templates = {
            "äº”è¨€ç»å¥": f"[{dynasty}][äº”è¨€ç»å¥]{prompt}",
            "ä¸ƒè¨€ç»å¥": f"[{dynasty}][ä¸ƒè¨€ç»å¥]{prompt}",
            "äº”è¨€å¾‹è¯—": f"[{dynasty}][äº”è¨€å¾‹è¯—]{prompt}",
            "ä¸ƒè¨€å¾‹è¯—": f"[{dynasty}][ä¸ƒè¨€å¾‹è¯—]{prompt}",
            "è¯": f"[{dynasty}][è¯]{prompt}",
        }
        return templates.get(style, f"[{dynasty}]{prompt}")

    def _post_process(self, text: str, style: str) -> str:
        """åå¤„ç†ç”Ÿæˆçš„è¯—è¯"""
        # ç§»é™¤æç¤ºè¯æ ‡è®°
        text = re.sub(r'\[.*?\]', '', text)

        # æ ¹æ®é£æ ¼æ ¼å¼åŒ–
        if "äº”è¨€ç»å¥" in style:
            # å››å¥ï¼Œæ¯å¥5å­—
            lines = self._split_by_punctuation(text)[:4]
            lines = [line[:5] for line in lines]
        elif "ä¸ƒè¨€ç»å¥" in style:
            # å››å¥ï¼Œæ¯å¥7å­—
            lines = self._split_by_punctuation(text)[:4]
            lines = [line[:7] for line in lines]
        elif "äº”è¨€å¾‹è¯—" in style:
            # å…«å¥ï¼Œæ¯å¥5å­—
            lines = self._split_by_punctuation(text)[:8]
            lines = [line[:5] for line in lines]
        elif "ä¸ƒè¨€å¾‹è¯—" in style:
            # å…«å¥ï¼Œæ¯å¥7å­—
            lines = self._split_by_punctuation(text)[:8]
            lines = [line[:7] for line in lines]
        else:
            lines = self._split_by_punctuation(text)

        # æ·»åŠ æ ‡ç‚¹
        formatted = "ï¼Œ\n".join(lines[:-1]) + "ã€‚"
        if len(lines) > 1:
            mid = len(lines) // 2
            formatted = "ï¼Œ\n".join(lines[:mid-1]) + "ã€‚\n" + \
                       "ï¼Œ\n".join(lines[mid:]) + "ã€‚"

        return formatted.strip()

    def _split_by_punctuation(self, text: str) -> list[str]:
        """æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å¥"""
        text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€]', '\n', text)
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        return lines


# FastAPIæ¥å£
@app.post("/ai/generate-poetry")
async def generate_poetry(request: PoetryGenerateRequest):
    """
    AIç”Ÿæˆè¯—è¯

    Request:
        {
            "prompt": "æ˜æœˆ",
            "style": "äº”è¨€ç»å¥",
            "dynasty": "å”ä»£",
            "num_return": 3
        }

    Response:
        {
            "poetries": [
                "æ˜æœˆç…§é«˜æ¥¼ï¼Œ\næµå…‰æ­£å¾˜å¾Šã€‚\nä¸Šæœ‰æ„æ€å¦‡ï¼Œ\næ‚²å¹æœ‰ä½™å“€ã€‚",
                "æ˜æœˆçšå¤œå…‰ï¼Œ\nä¿ƒç»‡é¸£ä¸œå£ã€‚\nç‰è¡¡æŒ‡å­Ÿå†¬ï¼Œ\nä¼—æ˜Ÿä½•å†å†ã€‚",
                ...
            ],
            "prompt": "æ˜æœˆ",
            "style": "äº”è¨€ç»å¥"
        }
    """
    generator = PoetryGenerator()

    poetries = await generator.generate(
        prompt=request.prompt,
        style=request.style,
        dynasty=request.dynasty,
        num_return=request.num_return
    )

    return {
        "poetries": poetries,
        "prompt": request.prompt,
        "style": request.style,
        "dynasty": request.dynasty
    }
```

#### å¼‚æ­¥ç”Ÿæˆï¼ˆCeleryï¼‰

å¯¹äºå¤§æ¨¡å‹ï¼ˆå¦‚ChatGLM-6Bï¼‰ï¼Œæ¨ç†æ—¶é—´è¾ƒé•¿ï¼Œåº”ä½¿ç”¨å¼‚æ­¥ä»»åŠ¡ï¼š

```python
from celery import Celery

celery_app = Celery('poetry', broker='redis://localhost:6379/0')

@celery_app.task
def generate_poetry_async(prompt: str, style: str, dynasty: str):
    """å¼‚æ­¥ç”Ÿæˆè¯—è¯"""
    generator = PoetryGenerator(model_name="THUDM/chatglm-6b")
    poetries = generator.generate(prompt, style, dynasty)
    return poetries

# APIæ¥å£
@app.post("/ai/generate-poetry-async")
async def generate_poetry_async_api(request: PoetryGenerateRequest):
    """å¼‚æ­¥ç”Ÿæˆè¯—è¯ï¼ˆè¿”å›ä»»åŠ¡IDï¼‰"""
    task = generate_poetry_async.delay(
        request.prompt,
        request.style,
        request.dynasty
    )

    return {
        "task_id": task.id,
        "status": "pending",
        "message": "è¯—è¯ç”Ÿæˆä¸­ï¼Œè¯·ç¨åæŸ¥è¯¢ç»“æœ"
    }

@app.get("/ai/task/{task_id}")
async def get_task_result(task_id: str):
    """æŸ¥è¯¢å¼‚æ­¥ä»»åŠ¡ç»“æœ"""
    task = celery_app.AsyncResult(task_id)

    if task.ready():
        return {
            "task_id": task_id,
            "status": "completed",
            "result": task.result
        }
    else:
        return {
            "task_id": task_id,
            "status": "pending",
            "message": "è¯—è¯ç”Ÿæˆä¸­..."
        }
```

---

### 2.3 æƒ…æ„Ÿåˆ†æ ğŸ˜ŠğŸ˜¢

#### åŠŸèƒ½æè¿°
åˆ†æè¯—è¯è¡¨è¾¾çš„æƒ…æ„Ÿï¼ˆå–œæ‚¦ã€æ‚²ä¼¤ã€æ€ä¹¡ã€çˆ±æƒ…ç­‰ï¼‰ã€‚

#### åº”ç”¨åœºæ™¯
- è¯—è¯è¯¦æƒ…é¡µå±•ç¤ºæƒ…æ„Ÿæ ‡ç­¾
- æŒ‰æƒ…æ„Ÿç­›é€‰è¯—è¯
- æƒ…æ„Ÿæ¨èï¼ˆæ ¹æ®ç”¨æˆ·æƒ…ç»ªæ¨èï¼‰

#### å®ç°ä»£ç 

```python
from transformers import pipeline
import torch

class SentimentAnalyzer:
    """è¯—è¯æƒ…æ„Ÿåˆ†æ"""

    def __init__(self):
        # åŠ è½½æƒ…æ„Ÿåˆ†ææ¨¡å‹
        self.analyzer = pipeline(
            "text-classification",
            model="uer/roberta-base-finetuned-chinanews-chinese",
            device=0 if torch.cuda.is_available() else -1
        )

        # æƒ…æ„Ÿæ˜ å°„
        self.emotion_map = {
            'LABEL_0': 'å–œæ‚¦',
            'LABEL_1': 'æ‚²ä¼¤',
            'LABEL_2': 'æ„¤æ€’',
            'LABEL_3': 'ææƒ§',
            'LABEL_4': 'æƒŠè®¶',
            'LABEL_5': 'åŒæ¶'
        }

        # è¯—è¯ç‰¹å®šæƒ…æ„Ÿå…³é”®è¯
        self.poetry_emotions = {
            'æ€ä¹¡': ['æ•…ä¹¡', 'å®¶ä¹¡', 'æ€å½’', 'ä¹¡æ„', 'æ¸¸å­'],
            'çˆ±æƒ…': ['ç›¸æ€', 'ç¦»åˆ«', 'æ€å›', 'æƒ…éƒ', 'ä½³äºº'],
            'è±ªæ”¾': ['å£®å¿—', 'è±ªæƒ…', 'æ°”å', 'ä¸‡é‡Œ', 'é•¿é£'],
            'å©‰çº¦': ['ç»†é›¨', 'è½»é£', 'å¹½æ€¨', 'å‡„ç¾', 'æŸ”æƒ…'],
            'ç”°å›­': ['ç”°å›­', 'å±±æ°´', 'æ¡ƒèŠ±', 'å†œå®¶', 'è€•ç§'],
            'è¾¹å¡': ['è¾¹å…³', 'æˆè¾¹', 'æ²™åœº', 'å¾æˆ˜', 'çƒ½ç«']
        }

    async def analyze(self, poetry_content: str) -> dict:
        """
        åˆ†æè¯—è¯æƒ…æ„Ÿ

        Returns:
            {
                "primary_emotion": "æ‚²ä¼¤",
                "secondary_emotions": ["æ€ä¹¡", "ç¦»åˆ«"],
                "score": 0.95,
                "keywords": ["æ˜æœˆ", "æ•…ä¹¡", "æ€å½’"],
                "description": "è¿™é¦–è¯—è¡¨è¾¾äº†è¯—äººå¯¹æ•…ä¹¡çš„æ·±åˆ‡æ€å¿µ"
            }
        """
        # 1. åŸºç¡€æƒ…æ„Ÿåˆ†æ
        result = self.analyzer(poetry_content[:512])[0]  # é™åˆ¶é•¿åº¦
        primary_emotion = self.emotion_map.get(result['label'], 'æœªçŸ¥')
        score = result['score']

        # 2. æå–è¯—è¯ç‰¹å®šæƒ…æ„Ÿ
        secondary_emotions = self._extract_poetry_emotions(poetry_content)

        # 3. æå–å…³é”®è¯
        keywords = self._extract_keywords(poetry_content)

        # 4. ç”Ÿæˆæƒ…æ„Ÿæè¿°
        description = self._generate_description(
            primary_emotion,
            secondary_emotions,
            keywords
        )

        return {
            "primary_emotion": primary_emotion,
            "secondary_emotions": secondary_emotions,
            "score": score,
            "keywords": keywords,
            "description": description
        }

    def _extract_poetry_emotions(self, text: str) -> list[str]:
        """æå–è¯—è¯ç‰¹å®šæƒ…æ„Ÿ"""
        emotions = []
        for emotion, keywords in self.poetry_emotions.items():
            if any(keyword in text for keyword in keywords):
                emotions.append(emotion)
        return emotions[:3]  # æœ€å¤š3ä¸ª

    def _extract_keywords(self, text: str) -> list[str]:
        """æå–å…³é”®è¯ï¼ˆç®€åŒ–ç‰ˆï¼Œå¯ç”¨jiebaä¼˜åŒ–ï¼‰"""
        # TODO: ä½¿ç”¨jiebaåˆ†è¯ + TF-IDFæå–å…³é”®è¯
        import jieba.analyse
        keywords = jieba.analyse.extract_tags(text, topK=5)
        return keywords

    def _generate_description(
        self,
        primary_emotion: str,
        secondary_emotions: list[str],
        keywords: list[str]
    ) -> str:
        """ç”Ÿæˆæƒ…æ„Ÿæè¿°"""
        templates = {
            'å–œæ‚¦': f"è¿™é¦–è¯—æ´‹æº¢ç€{primary_emotion}ä¹‹æƒ…",
            'æ‚²ä¼¤': f"è¿™é¦–è¯—æµéœ²å‡ºæ·±æ·±çš„{primary_emotion}",
            'æ€ä¹¡': f"è¿™é¦–è¯—è¡¨è¾¾äº†å¯¹æ•…ä¹¡çš„æ€å¿µ",
            'çˆ±æƒ…': f"è¿™é¦–è¯—æç»˜äº†åŠ¨äººçš„çˆ±æƒ…",
        }

        base = templates.get(
            primary_emotion,
            f"è¿™é¦–è¯—çš„ä¸»è¦æƒ…æ„Ÿæ˜¯{primary_emotion}"
        )

        if secondary_emotions:
            base += f"ï¼Œå¹¶è•´å«{ã€'.join(secondary_emotions)}ä¹‹æ„"

        if keywords:
            base += f"ï¼Œé€šè¿‡{keywords[0]}ç­‰æ„è±¡è¡¨ç°"

        return base + "ã€‚"


# APIæ¥å£
@app.post("/ai/analyze-sentiment")
async def analyze_sentiment(poetry_id: int):
    """åˆ†æè¯—è¯æƒ…æ„Ÿ"""
    # è·å–è¯—è¯å†…å®¹
    poetry = await db.get(Poetry, poetry_id)
    if not poetry:
        raise HTTPException(404, "è¯—è¯ä¸å­˜åœ¨")

    # åˆ†ææƒ…æ„Ÿ
    analyzer = SentimentAnalyzer()
    result = await analyzer.analyze(poetry.content)

    # ä¿å­˜åˆ°æ•°æ®åº“
    await db.execute(
        """
        UPDATE poetry
        SET emotion_primary = :primary,
            emotion_secondary = :secondary,
            emotion_keywords = :keywords
        WHERE id = :id
        """,
        {
            "primary": result['primary_emotion'],
            "secondary": json.dumps(result['secondary_emotions']),
            "keywords": json.dumps(result['keywords']),
            "id": poetry_id
        }
    )

    return result
```

---

### 2.4 è¯­ä¹‰æœç´¢ ğŸ”

#### åŠŸèƒ½æè¿°
ç”¨æˆ·è¾“å…¥"æå†™æ˜¥å¤©çš„è¯—"ï¼Œç³»ç»Ÿé€šè¿‡è¯­ä¹‰ç†è§£æ‰¾åˆ°ç›¸å…³è¯—è¯ï¼Œè€Œä¸æ˜¯ç®€å•çš„å…³é”®è¯åŒ¹é…ã€‚

#### æŠ€æœ¯æ–¹æ¡ˆ

```python
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

class SemanticSearchEngine:
    """è¯­ä¹‰æœç´¢å¼•æ“"""

    def __init__(self):
        # åŠ è½½Sentence-BERTæ¨¡å‹
        self.model = SentenceTransformer(
            'shibing624/text2vec-base-chinese'
        )

        # åŠ è½½Faisså‘é‡ç´¢å¼•
        self.index = faiss.read_index("data/poetry_vectors.index")

        # åŠ è½½è¯—è¯IDæ˜ å°„
        self.id_mapping = np.load("data/poetry_id_mapping.npy")

        # ç»´åº¦
        self.dimension = 768

    async def build_index(self, poetries: list):
        """
        æ„å»ºå‘é‡ç´¢å¼•ï¼ˆç¦»çº¿ä»»åŠ¡ï¼‰

        Args:
            poetries: [{'id': 1, 'title': '', 'content': ''}, ...]
        """
        # æå–æ–‡æœ¬
        texts = [
            f"{p['title']} {p['content']}"
            for p in poetries
        ]

        # æ‰¹é‡ç¼–ç 
        vectors = self.model.encode(
            texts,
            batch_size=32,
            show_progress_bar=True
        )

        # å½’ä¸€åŒ–ï¼ˆç”¨äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)

        # åˆ›å»ºFaissç´¢å¼•ï¼ˆä½¿ç”¨å†…ç§¯ï¼Œç›¸å½“äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        index = faiss.IndexFlatIP(self.dimension)
        index.add(vectors.astype('float32'))

        # ä¿å­˜
        faiss.write_index(index, "data/poetry_vectors.index")

        # ä¿å­˜IDæ˜ å°„
        id_mapping = np.array([p['id'] for p in poetries])
        np.save("data/poetry_id_mapping.npy", id_mapping)

        print(f"ç´¢å¼•æ„å»ºå®Œæˆï¼Œå…± {len(poetries)} é¦–è¯—è¯")

    async def search(
        self,
        query: str,
        top_k: int = 10,
        filters: dict = None
    ) -> list:
        """
        è¯­ä¹‰æœç´¢

        Args:
            query: æŸ¥è¯¢è¯­å¥ï¼Œå¦‚"æå†™æ˜¥å¤©çš„è¯—"
            top_k: è¿”å›æ•°é‡
            filters: è¿‡æ»¤æ¡ä»¶ï¼Œå¦‚ {"dynasty": "å”ä»£"}

        Returns:
            [
                {
                    'poetry_id': 123,
                    'score': 0.95,
                    'title': 'æ˜¥æ™“',
                    'content': '...'
                },
                ...
            ]
        """
        # 1. å°†æŸ¥è¯¢è½¬ä¸ºå‘é‡
        query_vector = self.model.encode([query])[0]
        query_vector = query_vector / np.linalg.norm(query_vector)  # å½’ä¸€åŒ–

        # 2. å‘é‡æ£€ç´¢
        scores, indices = self.index.search(
            np.array([query_vector], dtype='float32'),
            top_k * 3  # å¤šå–ä¸€äº›ï¼Œç”¨äºåç»­è¿‡æ»¤
        )

        # 3. è·å–è¯—è¯ID
        poetry_ids = self.id_mapping[indices[0]].tolist()

        # 4. ä»æ•°æ®åº“è·å–è¯—è¯è¯¦æƒ…
        poetries = await db.execute(
            """
            SELECT id, title, content, author, dynasty
            FROM poetry
            WHERE id IN :ids
            """,
            {"ids": tuple(poetry_ids)}
        )

        # 5. åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if filters:
            poetries = [
                p for p in poetries
                if all(
                    getattr(p, key) == value
                    for key, value in filters.items()
                )
            ]

        # 6. æ·»åŠ ç›¸ä¼¼åº¦åˆ†æ•°
        poetry_score_map = {
            pid: score
            for pid, score in zip(poetry_ids, scores[0])
        }

        results = [
            {
                'poetry_id': p.id,
                'title': p.title,
                'content': p.content,
                'author': p.author,
                'dynasty': p.dynasty,
                'score': float(poetry_score_map.get(p.id, 0))
            }
            for p in poetries[:top_k]
        ]

        return results


# APIæ¥å£
@app.get("/search/semantic")
async def semantic_search(
    query: str,
    top_k: int = 10,
    dynasty: str = None,
    poet: str = None
):
    """
    è¯­ä¹‰æœç´¢

    Examples:
        /search/semantic?query=æå†™æ˜¥å¤©çš„è¯—
        /search/semantic?query=æ€å¿µæ•…ä¹¡&dynasty=å”ä»£
    """
    search_engine = SemanticSearchEngine()

    # æ„å»ºè¿‡æ»¤æ¡ä»¶
    filters = {}
    if dynasty:
        filters['dynasty'] = dynasty
    if poet:
        filters['author'] = poet

    # æœç´¢
    results = await search_engine.search(query, top_k, filters)

    return {
        "query": query,
        "results": results,
        "total": len(results)
    }


# åå°ä»»åŠ¡ï¼šå®šæœŸé‡å»ºç´¢å¼•
@celery_app.task
def rebuild_search_index():
    """é‡å»ºæœç´¢ç´¢å¼•ï¼ˆæ¯å‘¨æ‰§è¡Œä¸€æ¬¡ï¼‰"""
    # è·å–æ‰€æœ‰è¯—è¯
    poetries = db.query(Poetry).all()

    # æ„å»ºç´¢å¼•
    engine = SemanticSearchEngine()
    asyncio.run(engine.build_index(poetries))
```

---

### 2.5 OCRè¯†åˆ« ğŸ“·

#### åŠŸèƒ½æè¿°
ç”¨æˆ·æ‹æ‘„å¤è¯—è¯å›¾ç‰‡ï¼Œç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«æ–‡å­—å¹¶åŒ¹é…è¯—è¯ã€‚

#### å®ç°ä»£ç 

```python
from paddleocr import PaddleOCR
from PIL import Image
import difflib

class PoetryOCR:
    """è¯—è¯OCRè¯†åˆ«"""

    def __init__(self):
        # åˆå§‹åŒ–PaddleOCR
        self.ocr = PaddleOCR(
            use_angle_cls=True,  # æ–‡æœ¬æ–¹å‘åˆ†ç±»
            lang='ch',           # ä¸­æ–‡
            use_gpu=torch.cuda.is_available()
        )

    async def recognize(self, image_path: str) -> dict:
        """
        è¯†åˆ«å›¾ç‰‡ä¸­çš„è¯—è¯

        Returns:
            {
                "text": "åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚ä¸¾å¤´æœ›æ˜æœˆï¼Œä½å¤´æ€æ•…ä¹¡ã€‚",
                "lines": ["åºŠå‰æ˜æœˆå…‰", "ç–‘æ˜¯åœ°ä¸Šéœœ", ...],
                "confidence": 0.96,
                "matched_poetry": {
                    "id": 123,
                    "title": "é™å¤œæ€",
                    "author": "æç™½",
                    "similarity": 0.98
                }
            }
        """
        # 1. OCRè¯†åˆ«
        result = self.ocr.ocr(image_path, cls=True)

        # 2. æå–æ–‡æœ¬å’Œç½®ä¿¡åº¦
        lines = []
        confidences = []

        for line in result:
            for word_info in line:
                text = word_info[1][0]  # æ–‡æœ¬
                conf = word_info[1][1]  # ç½®ä¿¡åº¦
                lines.append(text)
                confidences.append(conf)

        # åˆå¹¶æ–‡æœ¬
        full_text = "".join(lines)
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0

        # 3. æ¸…æ´—æ–‡æœ¬ï¼ˆå»é™¤æ ‡ç‚¹ã€ç©ºæ ¼ï¼‰
        cleaned_text = re.sub(r'[^\u4e00-\u9fa5]', '', full_text)

        # 4. åœ¨æ•°æ®åº“ä¸­åŒ¹é…è¯—è¯
        matched_poetry = await self._match_poetry(cleaned_text)

        return {
            "text": full_text,
            "lines": lines,
            "confidence": float(avg_confidence),
            "matched_poetry": matched_poetry
        }

    async def _match_poetry(self, text: str) -> dict:
        """
        åœ¨æ•°æ®åº“ä¸­åŒ¹é…è¯—è¯

        ä½¿ç”¨ç¼–è¾‘è·ç¦»ç®—æ³•æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è¯—è¯
        """
        # æŸ¥è¯¢æ‰€æœ‰è¯—è¯ï¼ˆä¼˜åŒ–ï¼šå¯ä»¥ç”¨Elasticsearché¢„ç­›é€‰ï¼‰
        poetries = await db.execute(
            """
            SELECT id, title, content, author
            FROM poetry
            WHERE LENGTH(content) BETWEEN :min AND :max
            """,
            {
                "min": len(text) - 20,
                "max": len(text) + 20
            }
        )

        # è®¡ç®—ç›¸ä¼¼åº¦
        best_match = None
        best_similarity = 0

        for poetry in poetries:
            # æ¸…æ´—è¯—è¯å†…å®¹
            poetry_text = re.sub(r'[^\u4e00-\u9fa5]', '', poetry.content)

            # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨difflibï¼‰
            similarity = difflib.SequenceMatcher(
                None,
                text,
                poetry_text
            ).ratio()

            if similarity > best_similarity:
                best_similarity = similarity
                best_match = poetry

        if best_match and best_similarity > 0.7:  # é˜ˆå€¼70%
            return {
                "id": best_match.id,
                "title": best_match.title,
                "content": best_match.content,
                "author": best_match.author,
                "similarity": float(best_similarity)
            }

        return None


# APIæ¥å£
@app.post("/ai/ocr")
async def recognize_poetry_image(file: UploadFile):
    """
    è¯†åˆ«è¯—è¯å›¾ç‰‡

    Request:
        multipart/form-data
        file: å›¾ç‰‡æ–‡ä»¶

    Response:
        {
            "text": "åºŠå‰æ˜æœˆå…‰...",
            "matched_poetry": {...}
        }
    """
    # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡
    file_path = f"/tmp/{file.filename}"
    with open(file_path, "wb") as f:
        f.write(await file.read())

    # OCRè¯†åˆ«
    ocr = PoetryOCR()
    result = await ocr.recognize(file_path)

    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
    os.remove(file_path)

    return result
```

---

## ä¸‰ã€AIæ¨¡å‹éƒ¨ç½²æ–¹æ¡ˆ

### 3.1 éƒ¨ç½²æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPIä¸»æœåŠ¡ï¼ˆ8000ç«¯å£ï¼‰          â”‚
â”‚  - ä¸šåŠ¡é€»è¾‘                              â”‚
â”‚  - è½»é‡AIæ¨¡å‹ï¼ˆæƒ…æ„Ÿåˆ†æã€åˆ†ç±»ç­‰ï¼‰          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“ HTTP/gRPC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      AIæ¨¡å‹æ¨ç†æœåŠ¡ï¼ˆGPUæœåŠ¡å™¨ï¼‰           â”‚
â”‚  - è¯—è¯ç”Ÿæˆï¼ˆChatGLM-6Bï¼‰                â”‚
â”‚  - å¤§æ¨¡å‹æ¨ç†                            â”‚
â”‚  ä½¿ç”¨ TorchServe / BentoML              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“ å¼‚æ­¥ä»»åŠ¡
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Celery Worker                    â”‚
â”‚  - å¼‚æ­¥AIä»»åŠ¡                            â”‚
â”‚  - æ‰¹é‡æ¨ç†                              â”‚
â”‚  - å®šæ—¶ä»»åŠ¡                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 è½»é‡æ¨¡å‹ï¼ˆCPUï¼‰vs å¤§æ¨¡å‹ï¼ˆGPUï¼‰

| æ¨¡å‹ç±»å‹ | éƒ¨ç½²ä½ç½® | æ¨ç†æ–¹å¼ | å“åº”æ—¶é—´ |
|---------|---------|---------|---------|
| æƒ…æ„Ÿåˆ†æ | FastAPIä¸»æœåŠ¡ | åŒæ­¥ | <100ms |
| æ–‡æœ¬åˆ†ç±» | FastAPIä¸»æœåŠ¡ | åŒæ­¥ | <100ms |
| è¯­ä¹‰æœç´¢ | FastAPIä¸»æœåŠ¡ | åŒæ­¥ | <50ms |
| è¯—è¯ç”Ÿæˆ(å°æ¨¡å‹) | FastAPIä¸»æœåŠ¡ | åŒæ­¥ | 1-2ç§’ |
| è¯—è¯ç”Ÿæˆ(å¤§æ¨¡å‹) | ç‹¬ç«‹GPUæœåŠ¡ | å¼‚æ­¥ | 5-10ç§’ |

### 3.3 æ¨¡å‹ä¼˜åŒ–æŠ€æœ¯

#### 1. æ¨¡å‹é‡åŒ–ï¼ˆå‡å°æ¨¡å‹å¤§å°ï¼‰

```python
from transformers import AutoModelForCausalLM
import torch

# åŠ è½½æ¨¡å‹æ—¶ä½¿ç”¨é‡åŒ–
model = AutoModelForCausalLM.from_pretrained(
    "model_name",
    load_in_8bit=True,  # 8ä½é‡åŒ–
    device_map="auto"
)

# æˆ–ä½¿ç”¨4ä½é‡åŒ–ï¼ˆéœ€è¦bitsandbytesï¼‰
model = AutoModelForCausalLM.from_pretrained(
    "model_name",
    load_in_4bit=True,
    device_map="auto"
)
```

**æ•ˆæœ**ï¼š
- 8ä½é‡åŒ–ï¼šæ¨¡å‹å¤§å°å‡åŠï¼Œé€Ÿåº¦æå‡20-30%
- 4ä½é‡åŒ–ï¼šæ¨¡å‹å¤§å°1/4ï¼Œé€Ÿåº¦æå‡50%+

#### 2. æ‰¹é‡æ¨ç†

```python
async def batch_predict(texts: list[str], batch_size: int = 32):
    """æ‰¹é‡é¢„æµ‹ï¼Œæé«˜ååé‡"""
    results = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch_results = model.predict(batch)
        results.extend(batch_results)
    return results
```

#### 3. æ¨¡å‹ç¼“å­˜

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def generate_poetry_cached(prompt: str, style: str):
    """ç¼“å­˜å¸¸è§è¯·æ±‚"""
    return model.generate(prompt, style)
```

---

## å››ã€AIåŠŸèƒ½å®æ–½è·¯çº¿å›¾

### é˜¶æ®µä¸€ï¼šåŸºç¡€AIï¼ˆ1-2å‘¨ï¼‰âœ…

**ç›®æ ‡**ï¼šå®ç°åŸºç¡€æ¨èå’Œæƒ…æ„Ÿåˆ†æ

1. ååŒè¿‡æ»¤æ¨èï¼ˆåŸºäºç”¨æˆ·è¡Œä¸ºï¼‰
2. æƒ…æ„Ÿåˆ†æï¼ˆRoBERTaå°æ¨¡å‹ï¼‰
3. æœä»£åˆ†ç±»ï¼ˆBERTï¼‰

**æŠ€æœ¯è¦æ±‚**ï¼šCPUå³å¯

---

### é˜¶æ®µäºŒï¼šé«˜çº§AIï¼ˆ2-3å‘¨ï¼‰ğŸš€

**ç›®æ ‡**ï¼šå¼•å…¥æ·±åº¦å­¦ä¹ æ¨èå’Œè¯­ä¹‰æœç´¢

1. æ·±åº¦å­¦ä¹ æ¨èæ¨¡å‹
2. è¯­ä¹‰æœç´¢ï¼ˆSentence-BERT + Faissï¼‰
3. OCRè¯†åˆ«ï¼ˆPaddleOCRï¼‰

**æŠ€æœ¯è¦æ±‚**ï¼šæ¨èGPUï¼ŒCPUä¹Ÿå¯è¿è¡Œ

---

### é˜¶æ®µä¸‰ï¼šç”ŸæˆAIï¼ˆ2-3å‘¨ï¼‰ğŸ¤–

**ç›®æ ‡**ï¼šAIè¯—è¯ç”Ÿæˆ

1. GPT-2å°æ¨¡å‹è¯—è¯ç”Ÿæˆï¼ˆCPUç‰ˆï¼‰
2. ChatGLMå¤§æ¨¡å‹ç”Ÿæˆï¼ˆGPUç‰ˆï¼‰
3. é£èŠ±ä»¤AIå¯¹æ‰‹

**æŠ€æœ¯è¦æ±‚**ï¼šå¿…é¡»GPU

---

### é˜¶æ®µå››ï¼šä¼˜åŒ–ä¸æ‰©å±•ï¼ˆæŒç»­ï¼‰ğŸ’

1. æ¨¡å‹å¾®è°ƒï¼ˆä½¿ç”¨è‡ªæœ‰æ•°æ®ï¼‰
2. A/Bæµ‹è¯•AIæ•ˆæœ
3. å¤šæ¨¡æ€AIï¼ˆå›¾æ–‡ç»“åˆï¼‰
4. çŸ¥è¯†å›¾è°±æ„å»º

---

## äº”ã€æ€»ç»“

### AIèƒ½åŠ›çŸ©é˜µ

| åŠŸèƒ½ | MVP | æˆç†ŸæœŸ | æœªæ¥ |
|------|-----|--------|------|
| **æ¨è** | ååŒè¿‡æ»¤ | æ·±åº¦å­¦ä¹  | å¼ºåŒ–å­¦ä¹  |
| **ç”Ÿæˆ** | GPT-2å°æ¨¡å‹ | ChatGLM | å¾®è°ƒå¤§æ¨¡å‹ |
| **æœç´¢** | å…³é”®è¯ | è¯­ä¹‰æœç´¢ | å¤šæ¨¡æ€æœç´¢ |
| **åˆ†æ** | è§„åˆ™å¼•æ“ | æ·±åº¦æ¨¡å‹ | å¤§è¯­è¨€æ¨¡å‹ |

### æŠ•å…¥äº§å‡ºæ¯”

| åŠŸèƒ½ | å¼€å‘æˆæœ¬ | æœåŠ¡å™¨æˆæœ¬ | ç”¨æˆ·ä»·å€¼ | ROI |
|------|---------|-----------|---------|-----|
| æ™ºèƒ½æ¨è | ä¸­ | ä½ | â­â­â­â­â­ | é«˜ |
| è¯­ä¹‰æœç´¢ | ä¸­ | ä½ | â­â­â­â­â­ | é«˜ |
| æƒ…æ„Ÿåˆ†æ | ä½ | ä½ | â­â­â­â­ | é«˜ |
| è¯—è¯ç”Ÿæˆ | é«˜ | é«˜ | â­â­â­â­â­ | ä¸­ |
| OCRè¯†åˆ« | ä¸­ | ä½ | â­â­â­ | ä¸­ |

**å»ºè®®ä¼˜å…ˆçº§**ï¼š
1. â­â­â­â­â­ æ™ºèƒ½æ¨è
2. â­â­â­â­â­ è¯­ä¹‰æœç´¢
3. â­â­â­â­ æƒ…æ„Ÿåˆ†æ
4. â­â­â­â­ è¯—è¯ç”Ÿæˆï¼ˆå°æ¨¡å‹å…ˆè¡Œï¼‰
5. â­â­â­ OCRè¯†åˆ«

---

**Python + AI = è¯—è¯å¹³å°çš„æ ¸å¿ƒç«äº‰åŠ›ï¼** ğŸ¤–ğŸ‰
